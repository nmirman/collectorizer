{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the Covetly MongoDB database\n",
    "\n",
    "In this notebook, we access the wishlist and collection data we need for the recommender system.  The data is aggregated from the MongoDB database at Covetly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import operator\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load databases\n",
    "db = open('db.txt', 'r').readline().split(',')\n",
    "domainDb = MongoClient(db[0], readPreference=\"secondary\")[db[1]]\n",
    "catalogDb = MongoClient(db[2], readPreference=\"secondary\")[db[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB Aggregation\n",
    "Here we extract the collection and wishlist data for all users.  To do this, we create an aggregation query.  The query takes some time to execute, so we split it into manageable chunks.  [truncated for brevity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating want list 557582 entries\n",
      "... processing [ 0 , 10000 ]\n",
      "... processing [ 10000 , 20000 ]\n",
      "... processing [ 20000 , 30000 ]\n",
      "... processing [ 30000 , 40000 ]\n",
      "... processing [ 40000 , 50000 ]\n",
      "done!\n",
      "generating have list:  1499952 entries\n",
      "... processing [ 0 , 10000 ]\n",
      "... processing [ 10000 , 20000 ]\n",
      "... processing [ 20000 , 30000 ]\n",
      "... processing [ 30000 , 40000 ]\n",
      "... processing [ 40000 , 50000 ]\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "skipsize = 10000\n",
    "\n",
    "# wishlists\n",
    "wantitems = domainDb[\"wantlistitems\"]\n",
    "nwantitems = wantitems.count()\n",
    "\n",
    "# collections\n",
    "haveitems = domainDb[\"collectionitems\"]\n",
    "nhaveitems = haveitems.count()\n",
    "\n",
    "# get wishlists\n",
    "print('generating want list', nwantitems, 'entries')\n",
    "n = 0\n",
    "want_list = []\n",
    "while n*skipsize <= nwantitems:\n",
    "    print('... processing [', n*skipsize, ',', (n+1)*skipsize, ']')\n",
    "    pipeline = [\n",
    "        {\"$skip\": n*skipsize},\n",
    "        {\"$limit\": skipsize},\n",
    "        {\"$group\": {\"_id\": \"$UserId\", \"items\": {\"$push\": \"$ItemId\"}, \"dates\": {\"$push\":\"$CreatedDate\" }}}\n",
    "    ]\n",
    "    want_list.extend(list(wantitems.aggregate(pipeline)))\n",
    "    n += 1\n",
    "print('done!')\n",
    "\n",
    "# get collections\n",
    "print('generating have list: ', nhaveitems, 'entries')\n",
    "n = 0\n",
    "have_list = []\n",
    "while n*skipsize <= nhaveitems:\n",
    "    print('... processing [', n*skipsize, ',', (n+1)*skipsize, ']')\n",
    "    pipeline = [\n",
    "        {\"$skip\": n*skipsize},\n",
    "        {\"$limit\": skipsize},\n",
    "        {\"$group\": {\"_id\": \"$UserId\", \"items\": {\"$push\": \"$ItemId\"}, \"dates\": {\"$push\":\"$CreatedDate\" }}}\n",
    "    ]\n",
    "    have_list.extend(list(haveitems.aggregate(pipeline)))\n",
    "    n += 1\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining collection and wishlist data\n",
    "The collection and wishlist data will be stored in separate files, but will eventually go into a single ratings matrix.  We need to make sure that we use the same indices and columns for both.\n",
    "\n",
    "[The database queries have been truncated above, so we are seeing only a fraction of the users and items.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users:  1543\n",
      "items:  4616\n"
     ]
    }
   ],
   "source": [
    "# find all users\n",
    "users = set()\n",
    "for w in want_list:\n",
    "    users.add(w['_id'])\n",
    "for h in have_list:\n",
    "    users.add(h['_id'])\n",
    "print('users: ', len(users))\n",
    "\n",
    "# find all items\n",
    "items = set()\n",
    "for w in want_list:\n",
    "    for i in w['items']:\n",
    "        items.add(i)\n",
    "for h in have_list:\n",
    "    for i in h['items']:\n",
    "        items.add(i)\n",
    "print('items: ', len(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV\n",
    "We save the data we need in csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wantitems = pd.DataFrame(index=users, columns=items)\n",
    "\n",
    "# populate df\n",
    "for w in want_list:\n",
    "    user = w['_id']\n",
    "    for i in range(len(w['items'])):\n",
    "        #df_wantitems.set_value(user, w['items'][i], w['dates'][i])\n",
    "        df_wantitems.set_value(user, w['items'][i], 1)#w['dates'][i])\n",
    "df_wantitems.fillna(0, inplace=True)\n",
    "\n",
    "# export to csv\n",
    "df_wantitems.to_csv('data/wishlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_haveitems = pd.DataFrame(index=users, columns=items)\n",
    "\n",
    "# populate df\n",
    "for h in have_list:\n",
    "    user = h['_id']\n",
    "    for i in range(len(h['items'])):\n",
    "        #df_haveitems.set_value(user, h['items'][i], h['dates'][i])\n",
    "        df_haveitems.set_value(user, h['items'][i], 1)#h['dates'][i]\n",
    "df_haveitems.fillna(0, inplace=True)\n",
    "\n",
    "# export to csv\n",
    "df_haveitems.to_csv('data/havelist.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
